{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "toxic-comment-9872-model.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "zkl6v_aJz1Et",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "eef32d3a-06d6-46f1-ce40-b71ea5728306",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523672967508,
          "user_tz": -480,
          "elapsed": 14934,
          "user": {
            "displayName": "consult chwong",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115539443264919672408"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Download the data from github into the workspace and install the Keras Library\n",
        "!rm -r toxic_comments_data\n",
        "!git clone https://github.com/consultchwong/toxic_comments_data.git\n",
        "!pip install -q keras\n",
        "!ls -ltr toxic_comments_data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'toxic_comments_data': No such file or directory\n",
            "Cloning into 'toxic_comments_data'...\n",
            "remote: Counting objects: 10, done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 6 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (10/10), done.\n",
            "total 132276\n",
            "-rw-r--r-- 1 root root       22 Apr 14 02:29 README.md\n",
            "-rw-r--r-- 1 root root  6279782 Apr 14 02:29 sample_submission.csv\n",
            "-rw-r--r-- 1 root root 60354593 Apr 14 02:29 test.csv\n",
            "-rw-r--r-- 1 root root 68802655 Apr 14 02:29 train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0humVu721ZVm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "db269d12-e7d6-4e7b-f546-e89e60c27c98",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523673011074,
          "user_tz": -480,
          "elapsed": 43532,
          "user": {
            "displayName": "consult chwong",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115539443264919672408"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!curl -O https://s3-us-west-1.amazonaws.com/fasttext-vectors/crawl-300d-2M.vec.zip\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1454M  100 1454M    0     0  36.3M      0  0:00:40  0:00:40 --:--:-- 42.2M\n",
            "crawl-300d-2M.vec.zip  datalab\ttoxic_comments_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hyakqpod5B1y",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "d5261444-8f31-43ad-f87b-f4bc3ac5d43c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523673053741,
          "user_tz": -480,
          "elapsed": 42610,
          "user": {
            "displayName": "consult chwong",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115539443264919672408"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip\n",
        "!ls -ltr"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-04-14 02:30:12--  http://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip [following]\n",
            "--2018-04-14 02:30:12--  https://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408741 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip’\n",
            "\n",
            "glove.twitter.27B.z  68%[============>       ] 986.63M  36.3MB/s    eta 13s    "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "glove.twitter.27B.z 100%[===================>]   1.42G  39.7MB/s    in 38s     \n",
            "\n",
            "2018-04-14 02:30:51 (37.8 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408741/1520408741]\n",
            "\n",
            "total 2973800\n",
            "-rw-r--r-- 1 root root 1520408741 Dec 23  2015 glove.twitter.27B.zip\n",
            "drwxr-xr-x 1 root root       4096 Mar 13 21:48 datalab\n",
            "drwxr-xr-x 3 root root       4096 Apr 14 02:29 toxic_comments_data\n",
            "-rw-r--r-- 1 root root 1524738214 Apr 14 02:30 crawl-300d-2M.vec.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2IgL0-0r3C-J",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "ed15509c-8aa9-41df-82ba-7e474844341f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523673106980,
          "user_tz": -480,
          "elapsed": 53190,
          "user": {
            "displayName": "consult chwong",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115539443264919672408"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install unzip\n",
        "!unzip crawl-300d-2M.vec.zip\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
            "Archive:  crawl-300d-2M.vec.zip\n",
            "  inflating: crawl-300d-2M.vec       \n",
            "crawl-300d-2M.vec      datalab\t\t      toxic_comments_data\n",
            "crawl-300d-2M.vec.zip  glove.twitter.27B.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "euTevUJa5IfK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "8c621776-b072-4394-8e2b-9c555ecbdf80",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523673155626,
          "user_tz": -480,
          "elapsed": 48600,
          "user": {
            "displayName": "consult chwong",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115539443264919672408"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip glove.twitter.27B.zip\n",
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.twitter.27B.zip\n",
            "  inflating: glove.twitter.27B.100d.txt  \n",
            "  inflating: glove.twitter.27B.200d.txt  \n",
            "  inflating: glove.twitter.27B.25d.txt  \n",
            "  inflating: glove.twitter.27B.50d.txt  \n",
            "crawl-300d-2M.vec      glove.twitter.27B.100d.txt  glove.twitter.27B.50d.txt\n",
            "crawl-300d-2M.vec.zip  glove.twitter.27B.200d.txt  glove.twitter.27B.zip\n",
            "datalab\t\t       glove.twitter.27B.25d.txt   toxic_comments_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jYcJYRPmEg59",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "03e6e8fb-c4ab-4a42-a066-eb0ae036d732",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523673160594,
          "user_tz": -480,
          "elapsed": 4922,
          "user": {
            "displayName": "consult chwong",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115539443264919672408"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.kaggle.com/c/8076/download/sample_submission.csv.zip\n",
        "!unzip sample_submission.csv.zip\n",
        "!ls -ltr"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-04-14 02:32:36--  https://www.kaggle.com/c/8076/download/sample_submission.csv.zip\n",
            "Resolving www.kaggle.com (www.kaggle.com)... 168.62.224.124\n",
            "Connecting to www.kaggle.com (www.kaggle.com)|168.62.224.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /account/login?ReturnUrl=%2fc%2f8076%2fdownload%2fsample_submission.csv.zip [following]\n",
            "--2018-04-14 02:32:37--  https://www.kaggle.com/account/login?ReturnUrl=%2fc%2f8076%2fdownload%2fsample_submission.csv.zip\n",
            "Reusing existing connection to www.kaggle.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8243 (8.0K) [text/html]\n",
            "Saving to: ‘sample_submission.csv.zip’\n",
            "\n",
            "sample_submission.c 100%[===================>]   8.05K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-04-14 02:32:37 (19.5 MB/s) - ‘sample_submission.csv.zip’ saved [8243/8243]\n",
            "\n",
            "Archive:  sample_submission.csv.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of sample_submission.csv.zip or\n",
            "        sample_submission.csv.zip.zip, and cannot find sample_submission.csv.zip.ZIP, period.\n",
            "total 11142356\n",
            "-rw-rw-r-- 1 root root  257699930 Dec 23  2015 glove.twitter.27B.25d.txt\n",
            "-rw-rw-r-- 1 root root 2057595650 Dec 23  2015 glove.twitter.27B.200d.txt\n",
            "-rw-rw-r-- 1 root root 1021671926 Dec 23  2015 glove.twitter.27B.100d.txt\n",
            "-rw-rw-r-- 1 root root  510889212 Dec 23  2015 glove.twitter.27B.50d.txt\n",
            "-rw-r--r-- 1 root root 1520408741 Dec 23  2015 glove.twitter.27B.zip\n",
            "-rw-r--r-- 1 root root 4516698366 Jul 31  2017 crawl-300d-2M.vec\n",
            "drwxr-xr-x 1 root root       4096 Mar 13 21:48 datalab\n",
            "drwxr-xr-x 3 root root       4096 Apr 14 02:29 toxic_comments_data\n",
            "-rw-r--r-- 1 root root 1524738214 Apr 14 02:30 crawl-300d-2M.vec.zip\n",
            "-rw-r--r-- 1 root root       8243 Apr 14 02:32 sample_submission.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4iqFMHPdK1Ff",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "outputId": "b71a3884-7c57-4bc9-ece0-bd118f5ecef4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523673182857,
          "user_tz": -480,
          "elapsed": 22190,
          "user": {
            "displayName": "consult chwong",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115539443264919672408"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "!pip install unidecode\n",
        "!pip install nltk\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-3.4.0-cp36-cp36m-manylinux1_x86_64.whl (22.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 22.6MB 59kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim)\n",
            "Collecting smart-open>=1.2.1 (from gensim)\n",
            "  Downloading smart_open-1.5.7.tar.gz\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim)\n",
            "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
            "  Downloading boto3-1.7.4-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 5.2MB/s \n",
            "\u001b[?25hCollecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
            "  Downloading boto-2.48.0-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 880kB/s \n",
            "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
            "  Downloading bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim)\n",
            "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
            "  Downloading jmespath-0.9.3-py2.py3-none-any.whl\n",
            "Collecting botocore<1.11.0,>=1.10.4 (from boto3->smart-open>=1.2.1->gensim)\n",
            "  Downloading botocore-1.10.4-py2.py3-none-any.whl (4.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 4.2MB 313kB/s \n",
            "\u001b[?25hCollecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
            "  Downloading s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim)\n",
            "Collecting docutils>=0.10 (from botocore<1.11.0,>=1.10.4->boto3->smart-open>=1.2.1->gensim)\n",
            "  Downloading docutils-0.14-py3-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<2.7.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.11.0,>=1.10.4->boto3->smart-open>=1.2.1->gensim)\n",
            "Building wheels for collected packages: smart-open, bz2file\n",
            "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/cf/54/36/b003d8c2d26aadffc21f0677009ed53cf9575a97fc71fbba76\n",
            "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/31/9c/20/996d65ca104cbca940b1b053299b68459391c01c774d073126\n",
            "Successfully built smart-open bz2file\n",
            "Installing collected packages: jmespath, docutils, botocore, s3transfer, boto3, boto, bz2file, smart-open, gensim\n",
            "Successfully installed boto-2.48.0 boto3-1.7.4 botocore-1.10.4 bz2file-0.98 docutils-0.14 gensim-3.4.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.5.7\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.0.22-py2.py3-none-any.whl (235kB)\n",
            "\u001b[K    100% |████████████████████████████████| 235kB 2.5MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.0.22\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ISmfla0Gu5mi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "3c9414c7-9ffe-4682-e38b-fa4db3b7abeb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523673193713,
          "user_tz": -480,
          "elapsed": 10804,
          "user": {
            "displayName": "consult chwong",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115539443264919672408"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "\n",
        "import gensim\n",
        "from collections import Counter\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout, Conv1D, Embedding, SpatialDropout1D, concatenate\n",
        "from keras.layers import GRU, LSTM,Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
        "from keras.layers import CuDNNLSTM, CuDNNGRU\n",
        "from keras.preprocessing import text, sequence\n",
        "\n",
        "from keras.callbacks import Callback\n",
        "from keras import optimizers\n",
        "from keras.layers import Lambda\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "import os\n",
        "os.environ['OMP_NUM_THREADS'] = '4'\n",
        "\n",
        "import gc\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from unidecode import unidecode\n",
        "\n",
        "import time\n",
        "\n",
        "eng_stopwords = set(stopwords.words(\"english\"))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /content/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hEtXJeR3u5ml",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# 1. preprocessing\n",
        "train = pd.read_csv('./toxic_comments_data/train.csv')\n",
        "test = pd.read_csv('./toxic_comments_data/test.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cZFNRpX9u5mn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#2.  remove non-ascii\n",
        "\n",
        "special_character_removal=re.compile(r'[^a-z\\?\\!\\#\\@\\%\\* ]',re.IGNORECASE)\n",
        "def clean_text(x):\n",
        "    x_ascii = unidecode(x)\n",
        "    x_clean = special_character_removal.sub('',x_ascii)\n",
        "    return x_clean\n",
        "\n",
        "train['clean_text'] = train['comment_text'].apply(lambda x: clean_text(str(x)))\n",
        "test['clean_text'] = test['comment_text'].apply(lambda x: clean_text(str(x)))\n",
        "\n",
        "X_train = train['clean_text'].fillna(\"something\").values\n",
        "y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n",
        "X_test = test['clean_text'].fillna(\"something\").values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bJ5fniayu5mp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def add_features(df):\n",
        "    \n",
        "    df['comment_text'] = df['comment_text'].apply(lambda x:str(x))\n",
        "    df['total_length'] = df['comment_text'].apply(len)\n",
        "    df['capitals'] = df['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\n",
        "    df['caps_vs_length'] = df.apply(lambda row: float(row['capitals'])/float(row['total_length']),\n",
        "                                axis=1)\n",
        "    df['num_words'] = df.comment_text.str.count('\\S+')\n",
        "    df['num_unique_words'] = df['comment_text'].apply(lambda comment: len(set(w for w in comment.split())))\n",
        "    df['words_vs_unique'] = df['num_unique_words'] / df['num_words']  \n",
        "\n",
        "    return df\n",
        "\n",
        "train = add_features(train)\n",
        "test = add_features(test)\n",
        "\n",
        "features = train[['caps_vs_length', 'words_vs_unique']].fillna(0)\n",
        "test_features = test[['caps_vs_length', 'words_vs_unique']].fillna(0)\n",
        "\n",
        "ss = StandardScaler()\n",
        "ss.fit(np.vstack((features, test_features)))\n",
        "features = ss.transform(features)\n",
        "test_features = ss.transform(test_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bqlGLvtdu5mr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8863acd-379f-4ca3-c1d4-e109a12a4502",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523673274247,
          "user_tz": -480,
          "elapsed": 35899,
          "user": {
            "displayName": "consult chwong",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115539443264919672408"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# For best score (Public: 9869, Private: 9865), change to max_features = 283759, maxlen = 900\n",
        "max_features = 10000\n",
        "maxlen = 50\n",
        "\n",
        "tokenizer = text.Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(X_train) + list(X_test))\n",
        "X_train_sequence = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_sequence = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "x_train = sequence.pad_sequences(X_train_sequence, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(X_test_sequence, maxlen=maxlen)\n",
        "print(len(tokenizer.word_index))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "457142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r-FmSt8Qu5mt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the FastText Web Crawl vectors\n",
        "EMBEDDING_FILE_FASTTEXT=\"./crawl-300d-2M.vec\"\n",
        "EMBEDDING_FILE_TWITTER=\"./glove.twitter.27B.200d.txt\"\n",
        "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index_ft = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE_FASTTEXT,encoding='utf-8'))\n",
        "embeddings_index_tw = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE_TWITTER,encoding='utf-8'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mILUaZMHu5mw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "spell_model = gensim.models.KeyedVectors.load_word2vec_format(EMBEDDING_FILE_FASTTEXT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KyFdKYfTu5mx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# This code is  based on: Spellchecker using Word2vec by CPMP\n",
        "# https://www.kaggle.com/cpmpml/spell-checker-using-word2vec\n",
        "\n",
        "words = spell_model.index2word\n",
        "\n",
        "w_rank = {}\n",
        "for i,word in enumerate(words):\n",
        "    w_rank[word] = i\n",
        "\n",
        "WORDS = w_rank\n",
        "\n",
        "# Use fast text as vocabulary\n",
        "def words(text): return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "def P(word): \n",
        "    \"Probability of `word`.\"\n",
        "    # use inverse of rank as proxy\n",
        "    # returns 0 if the word isn't in the dictionary\n",
        "    return - WORDS.get(word, 0)\n",
        "\n",
        "def correction(word): \n",
        "    \"Most probable spelling correction for word.\"\n",
        "    return max(candidates(word), key=P)\n",
        "\n",
        "def candidates(word): \n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
        "\n",
        "def known(words): \n",
        "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)\n",
        "\n",
        "def edits1(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "def edits2(word): \n",
        "    \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
        "\n",
        "def singlify(word):\n",
        "    return \"\".join([letter for i,letter in enumerate(word) if i == 0 or letter != word[i-1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EQXGK8oau5m0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words,501))\n",
        "\n",
        "something_tw = embeddings_index_tw.get(\"something\")\n",
        "something_ft = embeddings_index_ft.get(\"something\")\n",
        "\n",
        "something = np.zeros((501,))\n",
        "something[:300,] = something_ft\n",
        "something[300:500,] = something_tw\n",
        "something[500,] = 0\n",
        "\n",
        "def all_caps(word):\n",
        "    return len(word) > 1 and word.isupper()\n",
        "\n",
        "def embed_word(embedding_matrix,i,word):\n",
        "    embedding_vector_ft = embeddings_index_ft.get(word)\n",
        "    if embedding_vector_ft is not None: \n",
        "        if all_caps(word):\n",
        "            last_value = np.array([1])\n",
        "        else:\n",
        "            last_value = np.array([0])\n",
        "        embedding_matrix[i,:300] = embedding_vector_ft\n",
        "        embedding_matrix[i,500] = last_value\n",
        "        embedding_vector_tw = embeddings_index_tw.get(word)\n",
        "        if embedding_vector_tw is not None:\n",
        "            embedding_matrix[i,300:500] = embedding_vector_tw\n",
        "\n",
        "            \n",
        "# Fasttext vector is used by itself if there is no glove vector but not the other way around.\n",
        "for word, i in word_index.items():\n",
        "    \n",
        "    if i >= max_features: continue\n",
        "        \n",
        "    if embeddings_index_ft.get(word) is not None:\n",
        "        embed_word(embedding_matrix,i,word)\n",
        "    else:\n",
        "        # change to > 20 for better score.\n",
        "        if len(word) > 0:\n",
        "            embedding_matrix[i] = something\n",
        "        else:\n",
        "            word2 = correction(word)\n",
        "            if embeddings_index_ft.get(word2) is not None:\n",
        "                embed_word(embedding_matrix,i,word2)\n",
        "            else:\n",
        "                word2 = correction(singlify(word))\n",
        "                if embeddings_index_ft.get(word2) is not None:\n",
        "                    embed_word(embedding_matrix,i,word2)\n",
        "                else:\n",
        "                    embedding_matrix[i] = something     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C1tw1lmau5m3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class RocAucEvaluation(Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "        self.max_score = 0\n",
        "        self.not_better_count = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=1)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n",
        "            if (score > self.max_score):\n",
        "                print(\"*** New High Score (previous: %.6f) \\n\" % self.max_score)\n",
        "                model.save_weights(\"best_weights.h5\")\n",
        "                self.max_score=score\n",
        "                self.not_better_count = 0\n",
        "            else:\n",
        "                self.not_better_count += 1\n",
        "                if self.not_better_count > 3:\n",
        "                    print(\"Epoch %05d: early stopping, high score = %.6f\" % (epoch,self.max_score))\n",
        "                    self.model.stop_training = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mrYFeclXu5m5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def get_model(features,clipvalue=0.5,num_filters=40,dropout=0.5,embed_size=501):\n",
        "    features_input = Input(shape=(features.shape[1],))\n",
        "    inp = Input(shape=(maxlen, ))\n",
        "    \n",
        "    # Layer 1: concatenated fasttext and glove twitter embeddings.\n",
        "    x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
        "    \n",
        "    # Uncomment for best result\n",
        "    # Layer 2: SpatialDropout1D(0.5)\n",
        "    #x = SpatialDropout1D(dropout)(x)\n",
        "    \n",
        "    # Uncomment for best result\n",
        "    # Layer 3: Bidirectional CuDNNLSTM\n",
        "    #x = Bidirectional(LSTM(num_filters, return_sequences=True))(x)\n",
        "\n",
        "\n",
        "    # Layer 4: Bidirectional CuDNNGRU\n",
        "    x, x_h, x_c = Bidirectional(GRU(num_filters, return_sequences=True, return_state = True))(x)  \n",
        "    \n",
        "    # Layer 5: A concatenation of the last state, maximum pool, average pool and \n",
        "    # two features: \"Unique words rate\" and \"Rate of all-caps words\"\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    \n",
        "    x = concatenate([avg_pool, x_h, max_pool,features_input])\n",
        "    \n",
        "    # Layer 6: output dense layer.\n",
        "    outp = Dense(6, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = Model(inputs=[inp,features_input], outputs=outp)\n",
        "    adam = optimizers.adam(clipvalue=clipvalue)\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=adam,\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aCAeSDOBu5m7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "d13cbd6d-8459-4ee8-f390-24498b549956",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523676019829,
          "user_tz": -480,
          "elapsed": 1933758,
          "user": {
            "displayName": "consult chwong",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115539443264919672408"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model = get_model(features)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Used epochs=100 with early exiting for best score.\n",
        "epochs = 1\n",
        "gc.collect()\n",
        "K.clear_session()\n",
        "\n",
        "# Change to 3\n",
        "num_folds = 2 #number of folds\n",
        "\n",
        "predict = np.zeros((test.shape[0],6))\n",
        "\n",
        "# Uncomment for out-of-fold predictions\n",
        "#scores = []\n",
        "#oof_predict = np.zeros((train.shape[0],6))\n",
        "\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=239)\n",
        "\n",
        "for train_index, test_index in kf.split(x_train):\n",
        "    \n",
        "    kfold_y_train,kfold_y_test = y_train[train_index], y_train[test_index]\n",
        "    kfold_X_train = x_train[train_index]\n",
        "    kfold_X_features = features[train_index]\n",
        "    kfold_X_valid = x_train[test_index]\n",
        "    kfold_X_valid_features = features[test_index] \n",
        "    \n",
        "    model = get_model(features)\n",
        "    \n",
        "    ra_val = RocAucEvaluation(validation_data=([kfold_X_valid,kfold_X_valid_features], kfold_y_test), interval = 1)\n",
        "    \n",
        "    model.fit([kfold_X_train,kfold_X_features], kfold_y_train, batch_size=batch_size, epochs=epochs, verbose=1,\n",
        "             callbacks = [ra_val])\n",
        "    gc.collect()\n",
        "    \n",
        "    #model.load_weights(bst_model_path)\n",
        "    model.load_weights(\"best_weights.h5\")\n",
        "    \n",
        "    predict += model.predict([x_test,test_features], batch_size=batch_size,verbose=1) / num_folds\n",
        "    \n",
        "    #gc.collect()\n",
        "    # uncomment for out of fold predictions\n",
        "    #oof_predict[test_index] = model.predict([kfold_X_valid, kfold_X_valid_features],batch_size=batch_size, verbose=1)\n",
        "    #cv_score = roc_auc_score(kfold_y_test, oof_predict[test_index])\n",
        "    \n",
        "    #scores.append(cv_score)\n",
        "    #print('score: ',cv_score)\n",
        "\n",
        "print(\"Done\")\n",
        "#print('Total CV score is {}'.format(np.mean(scores)))    \n",
        "\n",
        "\n",
        "sample_submission = pd.read_csv(\"./toxic_comments_data/sample_submission.csv\")\n",
        "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "sample_submission[class_names] = predict\n",
        "sample_submission.to_csv('model_9872_baseline_submission.csv',index=False)\n",
        "\n",
        "# uncomment for out of fold predictions\n",
        "#oof = pd.DataFrame.from_dict({'id': train['id']})\n",
        "#for c in class_names:\n",
        "#    oof[c] = np.zeros(len(train))\n",
        "#    \n",
        "#oof[class_names] = oof_predict\n",
        "#for c in class_names:\n",
        "#    oof['prediction_' +c] = oof[c]\n",
        "#oof.to_csv('oof-model_9872_baseline_submission.csv', index=False)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "33216/79785 [===========>..................] - ETA: 5:05 - loss: 0.0697 - acc: 0.9768"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "71424/79785 [=========================>....] - ETA: 54s - loss: 0.0598 - acc: 0.9795"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "79785/79785 [==============================] - 522s 7ms/step - loss: 0.0586 - acc: 0.9798\n",
            "16992/79786 [=====>........................] - ETA: 1:57"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "79786/79786 [==============================] - 149s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.979093 \n",
            "\n",
            "*** New High Score (previous: 0.000000) \n",
            "\n",
            " 22656/153164 [===>..........................] - ETA: 4:03"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "152800/153164 [============================>.] - ETA: 0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "153164/153164 [==============================] - 285s 2ms/step\n",
            "Epoch 1/1\n",
            "19968/79786 [======>.......................] - ETA: 6:37 - loss: 0.0800 - acc: 0.9754"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "58272/79786 [====================>.........] - ETA: 2:22 - loss: 0.0618 - acc: 0.9794"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "79786/79786 [==============================] - 528s 7ms/step - loss: 0.0589 - acc: 0.9801\n",
            " 9216/79785 [==>...........................] - ETA: 2:13"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "79785/79785 [==============================] - 149s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.979297 \n",
            "\n",
            "*** New High Score (previous: 0.000000) \n",
            "\n",
            " 22656/153164 [===>..........................] - ETA: 4:04"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "153164/153164 [==============================] - 287s 2ms/step\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LcG1v3yIu5m9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "815272f5-ff41-4bff-a9c3-85080d14b427",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523676088896,
          "user_tz": -480,
          "elapsed": 69016,
          "user": {
            "displayName": "consult chwong",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115539443264919672408"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "from google.colab import files\n",
        "files.download('model_9872_baseline_submission.csv')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best_weights.h5\t\t    glove.twitter.27B.50d.txt\r\n",
            "crawl-300d-2M.vec\t    glove.twitter.27B.zip\r\n",
            "crawl-300d-2M.vec.zip\t    model_9872_baseline_submission.csv\r\n",
            "datalab\t\t\t    nltk_data\r\n",
            "glove.twitter.27B.100d.txt  sample_submission.csv.zip\r\n",
            "glove.twitter.27B.200d.txt  toxic_comments_data\r\n",
            "glove.twitter.27B.25d.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zp51WR8Ib4f1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "ab0d8f02-3f4e-42d0-bc0e-ba210f53e844",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523676090432,
          "user_tz": -480,
          "elapsed": 1471,
          "user": {
            "displayName": "consult chwong",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115539443264919672408"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 50)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 50, 501)      5010000     input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) [(None, 50, 80), (No 130080      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_2 (Glo (None, 80)           0           bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 80)           0           bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 2)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 202)          0           global_average_pooling1d_2[0][0] \n",
            "                                                                 bidirectional_2[0][1]            \n",
            "                                                                 global_max_pooling1d_2[0][0]     \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 6)            1218        concatenate_2[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 5,141,298\n",
            "Trainable params: 131,298\n",
            "Non-trainable params: 5,010,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V8pzr207icuX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "18180376-8eae-4643-d1b9-8017670b8062",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523676091407,
          "user_tz": -480,
          "elapsed": 749,
          "user": {
            "displayName": "consult chwong",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115539443264919672408"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "[x_test[1],test_features]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,   30, 1152,    1,  380,\n",
              "           8,  615,   17,   11,    8, 2579], dtype=int32),\n",
              " array([[-0.41690275, -0.07256174],\n",
              "        [ 0.8178728 ,  0.45904655],\n",
              "        [ 0.18732899, -0.1788834 ],\n",
              "        ...,\n",
              "        [-0.18198307, -0.45797774],\n",
              "        [-0.08293633, -0.88132311],\n",
              "        [-0.31764872,  0.50811808]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "gGguyGgznf9a",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1714
        },
        "outputId": "6a6670f2-72f2-4375-e3e4-20be76269995",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523676092476,
          "user_tz": -480,
          "elapsed": 911,
          "user": {
            "displayName": "consult chwong",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115539443264919672408"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.predict([x_test[:50],test_features[:50]], batch_size=batch_size,verbose=1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.66717958e-01, 2.00230256e-01, 8.39321256e-01, 8.24667886e-02,\n",
              "        8.62900496e-01, 3.41143221e-01],\n",
              "       [1.53357699e-03, 8.02898794e-05, 8.67742405e-04, 7.38007657e-05,\n",
              "        8.08726123e-04, 8.92745593e-05],\n",
              "       [5.01859467e-03, 4.11987246e-04, 4.18813853e-03, 1.20901433e-03,\n",
              "        2.95424857e-03, 3.68036097e-04],\n",
              "       [6.40263606e-04, 3.60585836e-05, 4.65302466e-04, 3.24578432e-05,\n",
              "        4.58594557e-04, 5.72177560e-05],\n",
              "       [5.74964145e-03, 2.02416224e-04, 2.63007986e-03, 3.65739194e-04,\n",
              "        1.93045463e-03, 3.66121007e-04],\n",
              "       [7.99907139e-04, 5.24294592e-05, 6.41387072e-04, 5.01861578e-05,\n",
              "        6.24158536e-04, 6.33795717e-05],\n",
              "       [9.87819117e-03, 2.21406866e-04, 2.53619789e-03, 1.81145137e-04,\n",
              "        5.63317025e-03, 3.27888294e-04],\n",
              "       [3.27033371e-01, 3.08449264e-03, 6.02484308e-02, 2.51750811e-03,\n",
              "        4.45216894e-02, 3.37032788e-03],\n",
              "       [7.10054487e-02, 4.65234771e-04, 7.18542514e-03, 9.73854039e-04,\n",
              "        2.23354604e-02, 2.40918901e-03],\n",
              "       [9.78714554e-04, 3.72401191e-05, 5.96683240e-04, 4.91405735e-05,\n",
              "        6.71226007e-04, 6.53181633e-05],\n",
              "       [1.32858112e-01, 8.58993037e-04, 4.16091233e-02, 6.98200078e-04,\n",
              "        2.10163966e-02, 6.05328998e-04],\n",
              "       [9.82048213e-02, 1.04615954e-03, 2.01358739e-02, 5.55391249e-04,\n",
              "        2.30565518e-02, 1.00362850e-02],\n",
              "       [3.16561502e-03, 4.10590910e-05, 6.76086056e-04, 2.52270092e-05,\n",
              "        1.30504405e-03, 9.26895300e-05],\n",
              "       [1.29087397e-03, 3.06425245e-05, 5.26216463e-04, 4.24318896e-05,\n",
              "        4.29227279e-04, 6.69016008e-05],\n",
              "       [6.39706093e-04, 2.71587433e-05, 3.36057419e-04, 1.16891679e-05,\n",
              "        3.02465167e-04, 2.70350192e-05],\n",
              "       [2.38419184e-03, 7.31111504e-05, 1.30938739e-03, 1.09746717e-04,\n",
              "        1.39604323e-03, 1.75478999e-04],\n",
              "       [7.75186811e-03, 4.41746786e-04, 2.75551877e-03, 6.88469969e-04,\n",
              "        3.14159761e-03, 7.00877106e-04],\n",
              "       [4.47426178e-03, 6.92798130e-05, 1.62606512e-03, 7.30340762e-05,\n",
              "        1.72424805e-03, 1.89138722e-04],\n",
              "       [3.50005249e-03, 5.40228284e-05, 1.63143699e-03, 3.18867933e-05,\n",
              "        1.43881061e-03, 1.01919330e-04],\n",
              "       [8.29246920e-03, 4.87776182e-04, 2.94868206e-03, 3.33637057e-04,\n",
              "        3.00539727e-03, 3.85988184e-04],\n",
              "       [6.38723746e-03, 1.92148334e-04, 2.45760498e-03, 2.89447722e-04,\n",
              "        1.49129925e-03, 3.23519751e-04],\n",
              "       [6.70947909e-01, 1.04181124e-02, 2.58342177e-01, 1.51498336e-02,\n",
              "        1.33623436e-01, 2.38957629e-02],\n",
              "       [3.91056575e-02, 7.90035760e-04, 4.88271285e-03, 2.11465359e-03,\n",
              "        1.41420728e-02, 3.80351441e-03],\n",
              "       [3.65995592e-03, 8.58958301e-05, 2.24510487e-03, 9.33475967e-05,\n",
              "        1.02081534e-03, 1.54834212e-04],\n",
              "       [2.14177594e-01, 1.70987751e-03, 5.01831025e-02, 1.35908742e-03,\n",
              "        4.19786610e-02, 4.14409442e-03],\n",
              "       [1.59014005e-03, 5.92590950e-05, 6.66479929e-04, 5.29558129e-05,\n",
              "        7.72191153e-04, 5.64946458e-05],\n",
              "       [1.66796183e-03, 7.41955009e-05, 9.59376630e-04, 1.09438646e-04,\n",
              "        9.22785723e-04, 1.21579091e-04],\n",
              "       [4.48929556e-02, 4.86121222e-04, 6.87688310e-03, 7.72647501e-04,\n",
              "        1.44638643e-02, 1.35170971e-03],\n",
              "       [1.89294383e-01, 3.26217036e-03, 2.41591968e-02, 3.85390036e-03,\n",
              "        5.75945079e-02, 7.79797509e-02],\n",
              "       [4.66636941e-03, 1.56127295e-04, 2.44482607e-03, 1.60690091e-04,\n",
              "        3.21502308e-03, 3.31952324e-04],\n",
              "       [1.22796057e-03, 7.59195245e-05, 4.73024615e-04, 9.64650826e-05,\n",
              "        8.41293659e-04, 7.85547309e-05],\n",
              "       [4.63287672e-03, 3.61163373e-04, 2.17690947e-03, 4.05712024e-04,\n",
              "        2.79416260e-03, 3.03488865e-04],\n",
              "       [1.82867842e-03, 5.28536984e-05, 6.93893060e-04, 3.49172042e-05,\n",
              "        9.58216959e-04, 5.99309496e-05],\n",
              "       [1.39198499e-03, 4.35872280e-05, 6.03075023e-04, 4.23960191e-05,\n",
              "        7.27445295e-04, 6.88998625e-05],\n",
              "       [3.54727656e-02, 4.79767518e-03, 2.01312620e-02, 9.10875946e-03,\n",
              "        1.72931328e-02, 5.50322141e-03],\n",
              "       [2.27503618e-03, 4.96384091e-05, 5.36523119e-04, 3.55719530e-05,\n",
              "        1.11598289e-03, 6.60837759e-05],\n",
              "       [4.26254584e-04, 2.77537947e-05, 3.61425482e-04, 2.81912435e-05,\n",
              "        4.95991320e-04, 7.05784041e-05],\n",
              "       [5.54725947e-03, 5.51499543e-04, 2.96021556e-03, 6.04327070e-04,\n",
              "        3.68940365e-03, 2.37948159e-04],\n",
              "       [6.54919267e-01, 3.69700007e-02, 6.37817621e-01, 4.23887745e-03,\n",
              "        3.36531907e-01, 3.57229747e-02],\n",
              "       [4.38963249e-03, 1.96811408e-04, 1.07367453e-03, 3.38212121e-04,\n",
              "        3.21268290e-03, 3.49424925e-04],\n",
              "       [2.41424330e-02, 9.84882121e-04, 8.30068439e-03, 1.20059948e-03,\n",
              "        7.18844309e-03, 9.46711632e-04],\n",
              "       [2.14010496e-02, 1.86803212e-04, 3.69041506e-03, 1.47940140e-04,\n",
              "        9.74239595e-03, 5.53553982e-04],\n",
              "       [1.07308547e-03, 9.94080692e-05, 8.64597154e-04, 7.28037776e-05,\n",
              "        8.09737830e-04, 8.39910717e-05],\n",
              "       [4.53581521e-03, 2.19805559e-04, 3.79162678e-03, 1.38283358e-04,\n",
              "        3.05183628e-03, 2.90851895e-04],\n",
              "       [7.52504617e-02, 1.46171660e-03, 2.75728013e-02, 7.36875983e-04,\n",
              "        1.91546474e-02, 1.53831334e-03],\n",
              "       [1.57015002e-03, 7.26305661e-05, 1.21533591e-03, 1.75308742e-04,\n",
              "        1.10263843e-03, 1.67626044e-04],\n",
              "       [4.89134388e-03, 6.74951807e-05, 1.21289399e-03, 9.09171140e-05,\n",
              "        1.60339300e-03, 2.33741477e-04],\n",
              "       [6.30086404e-04, 3.77942306e-05, 4.24417871e-04, 6.45294131e-05,\n",
              "        3.61160404e-04, 1.90016493e-04],\n",
              "       [9.70647454e-01, 7.60498792e-02, 8.80185306e-01, 8.08320194e-03,\n",
              "        6.59881234e-01, 1.23322234e-01],\n",
              "       [1.12621551e-02, 2.47864460e-04, 2.87375995e-03, 2.53148639e-04,\n",
              "        5.52235730e-03, 6.29727088e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "teNXM3tav2-c",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "19e454c4-68ec-475f-a8b0-cf8da078a3fd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523676093400,
          "user_tz": -480,
          "elapsed": 786,
          "user": {
            "displayName": "consult chwong",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115539443264919672408"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "test_features"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.41690275, -0.07256174],\n",
              "       [ 0.8178728 ,  0.45904655],\n",
              "       [ 0.18732899, -0.1788834 ],\n",
              "       ...,\n",
              "       [-0.18198307, -0.45797774],\n",
              "       [-0.08293633, -0.88132311],\n",
              "       [-0.31764872,  0.50811808]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "OuiQekD-y1zK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}